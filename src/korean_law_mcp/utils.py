import logging
import re
import concurrent.futures
import xmltodict
import requests
from .api_client import KoreanLawClient

# Configure logging
logger = logging.getLogger("korean-law-mcp")

# Initialize Client
client = KoreanLawClient()

# --- Helpers ---

def clean_html(text):
    if not text: return ""
    text = str(text)
    text = text.replace("<br/>", "\n").replace("&lt;", "<").replace("&gt;", ">")
    text = text.replace("<![CDATA[", "").replace("]]>", "")
    return text.strip()

def _parse_articles(law_info: dict) -> list[dict]:
    """
    Helper to parse articles from law info dictionary.
    Returns a list of dicts: {'no': str, 'title': str, 'full_text': str}
    """
    articles = []
    # Articles are in 'ì¡°ë¬¸' -> 'ì¡°ë¬¸ë‹¨ìœ„'
    try:
        jomun_section = law_info.get('ì¡°ë¬¸', {})
        if not jomun_section:
            return []

        body = jomun_section.get('ì¡°ë¬¸ë‹¨ìœ„', [])
        if not isinstance(body, list):
            body = [body]
            
        for item in body:
            # Check for 'ì¡°ë¬¸ë‚´ìš©' (Article Content)
            content = item.get('ì¡°ë¬¸ë‚´ìš©', '')
            # If empty, sometimes content is in text node or formatted differently
            if not content and '#text' in item:
                content = item['#text']
            
            content = content.strip()
            
            article_no = item.get('ì¡°ë¬¸ë²ˆí˜¸', '?')
            title = item.get('ì¡°ë¬¸ì œëª©', '')
            
            full_text_lines = []
            
            if title:
                header_text = f"ì œ{article_no}ì¡°({title})"
            else:
                header_text = f"ì œ{article_no}ì¡°"
            
            # Prevent duplication if content already starts with the header
            # Normalize spaces for comparison
            normalized_content = content.replace(" ", "")
            normalized_header = header_text.replace(" ", "")
            
            if normalized_content.startswith(normalized_header):
                # formatting: "Title: Title content..."
                # If content is exactly the header, maybe it's just a title line?
                # We'll just use the content as is, but often we want to format it nicely.
                # If we prepended header, it would be "Title: Title content..." -> Duplicate.
                # So we just use content.
                full_text_lines.append(content)
            else:
                full_text_lines.append(f"{header_text}: {content}")
            
            # Sub-paragraphs (í•­)
            paragraphs = item.get('í•­', [])
            if not isinstance(paragraphs, list):
                paragraphs = [paragraphs]
            
            for p in paragraphs:
                p_content = p.get('í•­ë‚´ìš©', '').strip()
                p_no = p.get('í•­ë²ˆí˜¸', '')
                if p_content:
                    # Sometimes p_content also starts with p_no (e.g. "â‘  Text")
                    if p_content.startswith(p_no):
                        full_text_lines.append(f"  {p_content}")
                    else:
                        full_text_lines.append(f"  {p_no}. {p_content}")
                    
                # Sub-sub-paragraphs (í˜¸) are inside 'í•­' -> 'í˜¸'
                hos = p.get('í˜¸', [])
                if not isinstance(hos, list):
                    hos = [hos]
                for h in hos:
                    h_content = h.get('í˜¸ë²ˆí˜¸', '') + " " + h.get('í˜¸ë‚´ìš©', '').strip()
                    h_content = h_content.strip()
                    full_text_lines.append(f"    {h_content}")
            
            # Deduplicate items in TOC generation
            # We can't easily dedupe here, but we can ensure we don't produce empty entries
            
            # Extract 'ì¡°ë¬¸ì—¬ë¶€' to distinguish between headers ("ì „ë¬¸") and content ("ì¡°ë¬¸")
            art_type = item.get('ì¡°ë¬¸ì—¬ë¶€', '')
            
            articles.append({
                'no': str(article_no),
                'title': title,
                'full_text': "\n".join(full_text_lines),
                'type': art_type
            })

    except Exception as e:
        logger.error(f"Error parsing articles: {e}")
        return []
        
    return articles

# --- Internal Implementations ---

def search_statute_internal(query: str) -> str:
    # Original search_statute logic
    logger.info(f"Searching for: {query}")
    data = client.search_law(query)
    if 'LawSearch' not in data or 'law' not in data['LawSearch']:
        return "No results found."
    laws = data['LawSearch']['law']
    if not isinstance(laws, list): laws = [laws]
    output = []
    for law in laws:
        name = law.get('ë²•ë ¹ëª…í•œê¸€', 'Unknown')
        id = law.get('ë²•ë ¹ì¼ë ¨ë²ˆí˜¸', 'Unknown') 
        date = law.get('ê³µí¬ì¼ìž', 'Unknown')
        output.append(f"ID: statute:{id} | Name: {name} | Date: {date}")
    return "\n".join(output)

def get_statute_detail_internal(law_id: str) -> str:
    logger.info(f"Getting details for ID: {law_id}")
    data = client.get_law_detail(law_id)
    if 'ë²•ë ¹' not in data: return "Error: Law not found."
    law_info = data['ë²•ë ¹']
    name = law_info.get('ê¸°ë³¸ì •ë³´', {}).get('ë²•ë ¹ëª…_í•œê¸€', 'Unknown')
    parsed_articles = _parse_articles(law_info)
    if not parsed_articles: return f"# {name}\n\n(No articles found)"
    articles_text = [a['full_text'] for a in parsed_articles]
    return f"# {name}\n\n" + "\n".join(articles_text)

def get_statute_article_internal(law_id: str, article_no: str) -> str:
    """
    Get the full text of a specific article from a statute.
    Args:
        law_id: The ID of the law (from search_statute).
        article_no: The article number (e.g., "20", "20-2").
    """
    logger.info(f"Getting article {article_no} for law ID: {law_id}")
    data = client.get_law_detail(law_id)
    
    if 'ë²•ë ¹' not in data:
        return "Error: Invalid response structure (Missing 'ë²•ë ¹')"
        
    law_info = data['ë²•ë ¹']
    name = law_info.get('ê¸°ë³¸ì •ë³´', {}).get('ë²•ë ¹ëª…_í•œê¸€', 'Unknown')
    
    parsed_articles = _parse_articles(law_info)
    
    for art in parsed_articles:
        if art['no'] == article_no:
            # If we find a content article, return immediately. 
            # If we find a header, store it but keep looking.
            if art.get('type') == 'ì¡°ë¬¸':
                return f"# {name} ì œ{article_no}ì¡°\n\n" + art['full_text']
            
            # If we haven't found a content article yet, maybe this header is the best we got?
            # But usually we want to keep looking.
            pass
            
    # Second pass: if we are here, we didn't find "ì¡°ë¬¸". Return the first match (header) if any.
    for art in parsed_articles:
        if art['no'] == article_no:
             return f"# {name} ì œ{article_no}ì¡°\n\n" + art['full_text']

    return f"Article {article_no} not found in {name}."

def get_precedent_detail_internal(prec_id: str) -> str:
    logger.info(f"Getting precedent details for ID: {prec_id}")
    data = client.get_precedent_detail(prec_id)
    
    if 'PrecService' not in data:
        # Fallback: Try with MST parameter
        # Some older precedents or specific IDs require MST instead of ID
        logger.info(f"Standard fetch failed for {prec_id}. Trying MST fallback...")
        try:
            url = f"{client.BASE_URL}/DRF/lawService.do"
            params = {
                "OC": client.user_id,
                "target": "prec",
                "type": "XML",
                "MST": prec_id 
            }
            resp = requests.get(url, params=params)
            data = xmltodict.parse(resp.content)
        except Exception as e:
            logger.error(f"MST fallback failed: {e}")
    
    if 'PrecService' not in data:
        # Fallback: Try with MST parameter again (Redundant block in original, but keeping logic safe)
        logger.info(f"Standard fetch failed (ID={prec_id}). Trying MST fallback...")
        # (Skipping duplicate try-except block, assuming previous one covered it or intention was retry)
        # Actually in original code it was duplicated. I'll just check once effectively.
        pass
            
    if 'PrecService' not in data:
        # Final Fallback: Check if it's actually a Constitutional Court decision (target='detc')
        # Sometimes 'prec' search returns const court cases but they must be fetched via 'detc'.
        logger.info(f"Prec fetch failed. Checking if ID={prec_id} is a Constitutional Court decision...")
        detc_content = get_prec_const_detail_internal(prec_id)
        if "Error" not in detc_content[:20]:
            return detc_content
            
        return "Error: Law/Precedent not found or Invalid ID. (Tried ID, MST, and Detc conversion)"
        
    info = data['PrecService']
    title = info.get('ì‚¬ê±´ëª…', 'Unknown')
    case_no = info.get('ì‚¬ê±´ë²ˆí˜¸', 'Unknown')
    date = info.get('ì„ ê³ ì¼ìž', 'Unknown')
    court = info.get('ë²•ì›ëª…', 'Unknown')
    summary = info.get('íŒê²°ìš”ì§€', '')
    content = info.get('íŒë¡€ë‚´ìš©', '')
    holding = info.get('íŒì‹œì‚¬í•­', '')
    
    # --- Knowledge Graph: Relationships ---
    ref_articles = info.get('ì°¸ì¡°ì¡°ë¬¸', '')
    ref_cases = info.get('ì°¸ì¡°íŒë¡€', '')

    output = [
        f"# {title}",
        f"**Case No:** {case_no}",
        f"**Court:** {court}",
        f"**Date:** {date}",
        f"**ID:** {prec_id}",
        "",
        "## íŒì‹œì‚¬í•­ (Holding)",
        clean_html(holding),
        "",
        "## íŒê²°ìš”ì§€ (Summary)",
        clean_html(summary),
        "",
        "## ì „ë¬¸ (Full Text)",
        clean_html(content)
    ]
    
    # Append Knowledge Graph Links
    if ref_articles or ref_cases:
        output.append("")
        output.append("## ì°¸ì¡° ì •ë³´ (Related Resources)")
        if ref_articles:
            output.append(f"### ì°¸ì¡° ì¡°ë¬¸ (Referenced Articles)\n{clean_html(ref_articles)}")
        if ref_cases:
            output.append(f"### ì°¸ì¡° íŒë¡€ (Referenced Cases)\n{clean_html(ref_cases)}")
            
    return "\n".join(output)

def get_admin_rule_detail_internal(adm_id: str) -> str:
    logger.info(f"Getting admin rule details for ID: {adm_id}")
    data = client.get_admin_rule_detail(adm_id)
    if 'AdmRulService' not in data: return "Error: Invalid response structure (Missing 'AdmRulService')"
    root = data['AdmRulService']
    info = root.get('í–‰ì •ê·œì¹™ê¸°ë³¸ì •ë³´', {})
    name = info.get('í–‰ì •ê·œì¹™ëª…', 'Unknown')
    dept = info.get('ì†Œê´€ë¶€ì²˜ëª…', '')
    
    content_acc = []

    if 'ì¡°ë¬¸ë‚´ìš©' in root:
        content = root['ì¡°ë¬¸ë‚´ìš©']
        if isinstance(content, str): content_acc.append(clean_html(content))
        elif isinstance(content, list):
             for c in content: content_acc.append(clean_html(str(c)))
    
    if not content_acc:
        full_text = root.get('ì „ë¬¸', '')
        if full_text: content_acc.append(clean_html(full_text))
            
    if not content_acc:
        buchik = root.get('ë¶€ì¹™')
        if buchik: content_acc.append("\n[ë¶€ì¹™]\n" + clean_html(str(buchik)))
        else: content_acc.append("(No content found.)")
        
    return f"# {name} ({dept})\n\n" + "\n".join(content_acc)

def get_prec_const_detail_internal(detc_id: str) -> str:
    logger.info(f"Getting const. decision details for ID: {detc_id}")
    data = client.get_prec_const_detail(detc_id)
    if 'DetcService' not in data: return "Error: Invalid response structure (Missing 'DetcService')"
    info = data['DetcService']
    title = info.get('ì‚¬ê±´ëª…', 'Unknown')
    case_no = info.get('ì‚¬ê±´ë²ˆí˜¸', 'Unknown')
    date = info.get('ì¢…êµ­ì¼ìž', 'Unknown')
    type_name = info.get('ì‚¬ê±´ì¢…ë¥˜ëª…', '')
    holding = info.get('íŒì‹œì‚¬í•­', '')
    summary = info.get('ê²°ì •ìš”ì§€', '') # Constitutional Court uses ê²°ì •ìš”ì§€
    content = info.get('ì „ë¬¸', '') # Constitutional Court uses ì „ë¬¸
    
    output = [
        f"# {title}",
        f"**Case No:** {case_no}",
        f"**Type:** {type_name}",
        f"**Date:** {date}",
        "",
        "## íŒì‹œì‚¬í•­ (Holding)",
        clean_html(holding),
        "",
        "## ê²°ì •ìš”ì§€ (Summary)",
        clean_html(summary),
        "",
        "## ì „ë¬¸ (Full Text)",
        clean_html(content)
    ]
    return "\n".join(output)

def get_autonomous_law_detail_internal(law_id: str) -> str:
    logger.info(f"Getting autonomous law details for ID: {law_id}")
    data = client.get_autonomous_law_detail(law_id)
    if 'LawService' not in data: return "Error: Invalid response structure (Missing 'LawService')"
    
    root = data['LawService']
    info = root.get('ìžì¹˜ë²•ê·œê¸°ë³¸ì •ë³´', {})
    name = info.get('ìžì¹˜ë²•ê·œëª…', 'Unknown')
    gov = info.get('ì§€ìžì²´ê¸°ê´€ëª…', '')
    
    articles = []
    jomun_section = root.get('ì¡°ë¬¸', {})
    if jomun_section:
        body = jomun_section.get('ì¡°ë¬¸ë‹¨ìœ„') or jomun_section.get('ì¡°') or []
        if not isinstance(body, list): body = [body]
        for item in body:
            content = item.get('ì¡°ë¬¸ë‚´ìš©') or item.get('ì¡°ë‚´ìš©') or ''
            content = content.strip()
            if not content and '#text' in item: content = item['#text'].strip()
            no = item.get('ì¡°ë¬¸ë²ˆí˜¸', '?')
            title = item.get('ì¡°ë¬¸ì œëª©') or item.get('ì¡°ì œëª©') or ''
            header = f"ì œ{no}ì¡°({title})" if title else f"ì œ{no}ì¡°"
            articles.append(f"{header}: {content}")
            if 'í•­' in item:
                paragraphs = item['í•­']
                if not isinstance(paragraphs, list): paragraphs = [paragraphs]
                for p in paragraphs:
                    p_content = p.get('í•­ë‚´ìš©', '').strip()
                    p_no = p.get('í•­ë²ˆí˜¸', '')
                    if p_content: articles.append(f"  {p_no}. {p_content}")
    if not articles: articles.append("(No parsed articles found. The law might use a different structure or be empty.)")
    return f"# {name} ({gov})\n\n" + "\n".join(articles)

def get_legal_term_detail_internal(term_id: str) -> str:
    logger.info(f"Getting legal term details for ID: {term_id}")
    data = client.get_legal_term_detail(term_id)
    
    if 'LawTermService' not in data: return "Error: Law Term not found."
    
    info = data['LawTermService']
    name = info.get('ë²•ë ¹ìš©ì–´ëª…', 'Unknown')
    desc = info.get('ë²•ë ¹ìš©ì–´ë‚´ìš©', '') # Definition
    source = info.get('ì¶œì²˜ë²•ë ¹ëª…', '')
    
    # Search metadata like which article defines it
    article_ref = info.get('ìš©ì–´ì •ì˜ì¡°ë¬¸', '') # Sometimes present
    
    return f"# {name}\n\n**Source:** {source}\n**Ref:** {article_ref}\n\n## Definition\n{desc}"

def get_statutory_interpretation_detail_internal(interp_id: str) -> str:
    logger.info(f"Getting interpretation details for ID: {interp_id}")
    data = client.get_statutory_interpretation_detail(interp_id)
    
    if 'ExpcService' not in data: return "Error: Interpretation not found."
    
    info = data['ExpcService']
    title = info.get('ì•ˆê±´ëª…', 'Unknown')
    no = info.get('ì•ˆê±´ë²ˆí˜¸', '')
    date = info.get('íšŒì‹ ì¼ìž', '')
    
    # Content fields
    question = info.get('ì§ˆì˜ìš”ì§€', '')
    answer = info.get('íšŒë‹µ', '')
    reason = info.get('ì´ìœ ', '')
    
    output = [
        f"# {title}",
        f"**Case No:** {no}",
        f"**Date:** {date}",
        "",
        "## ì§ˆì˜ìš”ì§€ (Question)",
        clean_html(question),
        "",
        "## íšŒë‹µ (Answer)",
        clean_html(answer),
        "",
        "## ì´ìœ  (Reasoning)",
        clean_html(reason)
    ]
    
    return "\n".join(output)

def get_law_history_internal(law_id: str, article_no: str = None) -> str:
    """
    Get the revision history of a law.
    Since the lsHistory API is not available, we extract revision info from the main law data.
    """
    logger.info(f"Getting law history for ID: {law_id}")
    
    try:
        # Use the regular law detail API which contains revision info
        data = client.get_law_detail(law_id)
    except Exception as e:
        logger.error(f"Error fetching law detail: {e}")
        return f"Error: Failed to fetch law information. {e}"
    
    if 'ë²•ë ¹' not in data:
        return "Error: Law not found."
    
    law_info = data['ë²•ë ¹']
    basic_info = law_info.get('ê¸°ë³¸ì •ë³´', {})
    
    law_name = basic_info.get('ë²•ë ¹ëª…_í•œê¸€', 'Unknown')
    enforcement_date = basic_info.get('ì‹œí–‰ì¼ìž', '')
    promulgation_date = basic_info.get('ê³µí¬ì¼ìž', '')
    promulgation_no = basic_info.get('ê³µí¬ë²ˆí˜¸', '')
    revision_type = basic_info.get('ì œê°œì •êµ¬ë¶„', '')
    
    output = [f"# {law_name} ì—°í˜ ì •ë³´", ""]
    
    output.append("## í˜„í–‰ ë²•ë ¹ ì •ë³´")
    output.append(f"- **ì œê°œì •êµ¬ë¶„**: {revision_type}")
    output.append(f"- **ì‹œí–‰ì¼ìž**: {enforcement_date}")
    output.append(f"- **ê³µí¬ì¼ìž**: {promulgation_date}")
    output.append(f"- **ê³µí¬ë²ˆí˜¸**: {promulgation_no}")
    output.append("")
    
    # ê°œì •ë¬¸ (Amendment document)
    amend_doc = law_info.get('ê°œì •ë¬¸', {})
    if amend_doc:
        amend_content = amend_doc.get('ê°œì •ë¬¸ë‚´ìš©', '')
        if amend_content:
            output.append("## ê°œì •ë¬¸")
            output.append(clean_html(amend_content)[:500])
            if len(amend_content) > 500:
                output.append("...")
            output.append("")
    
    # ì œê°œì •ì´ìœ  (Reason for amendment)
    reason_doc = law_info.get('ì œê°œì •ì´ìœ ', {})
    if reason_doc:
        reason_content = reason_doc.get('ì œê°œì •ì´ìœ ë‚´ìš©', '')
        if reason_content:
            output.append("## ì œê°œì •ì´ìœ ")
            output.append(clean_html(reason_content)[:1000])
            if len(reason_content) > 1000:
                output.append("...")
            output.append("")
    
    output.append("> **Note**: ì „ì²´ ì—°í˜ ì •ë³´ëŠ” [ë²•ë ¹ì •ë³´ì„¼í„°](https://www.law.go.kr)ì—ì„œ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")
    
    return "\n".join(output)

def get_old_new_comparison_internal(law_id: str) -> str:
    """
    Get the old/new article comparison (ì‹ êµ¬ì¡°ë¬¸ëŒ€ë¹„) for a law.
    Since the lsOnC API is not available, we provide web links and amendment info.
    """
    logger.info(f"Getting old/new comparison for ID: {law_id}")
    
    # Use the regular law detail API to get amendment info
    try:
        data = client.get_law_detail(law_id)
    except Exception as e:
        logger.error(f"Error fetching law detail: {e}")
        return f"Error: Failed to fetch law information. {e}"
    
    if 'ë²•ë ¹' not in data:
        return "Error: Law not found."
    
    law_info = data['ë²•ë ¹']
    basic_info = law_info.get('ê¸°ë³¸ì •ë³´', {})
    
    law_name = basic_info.get('ë²•ë ¹ëª…_í•œê¸€', 'Unknown')
    enforcement_date = basic_info.get('ì‹œí–‰ì¼ìž', '')
    revision_type = basic_info.get('ì œê°œì •êµ¬ë¶„', '')
    
    output = [f"# {law_name} ì‹ êµ¬ì¡°ë¬¸ëŒ€ë¹„", ""]
    
    # Amendment document contains the actual changes
    amend_doc = law_info.get('ê°œì •ë¬¸', {})
    if amend_doc:
        amend_content = amend_doc.get('ê°œì •ë¬¸ë‚´ìš©', '')
        if amend_content:
            output.append("## ìµœê·¼ ê°œì • ë‚´ìš©")
            output.append(f"- **ì œê°œì •êµ¬ë¶„**: {revision_type}")
            output.append(f"- **ì‹œí–‰ì¼ìž**: {enforcement_date}")
            output.append("")
            output.append("### ê°œì •ë¬¸")
            output.append("```")
            # Clean and show the amendment content
            clean_content = clean_html(amend_content)
            output.append(clean_content[:2000])
            if len(clean_content) > 2000:
                output.append("...")
            output.append("```")
            output.append("")
    
    # Provide web link for detailed comparison
    output.append("## ðŸ“Ž ì‹ êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œ í™•ì¸")
    output.append("")
    output.append("> **Note**: ìƒì„¸í•œ ì‹ êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œëŠ” êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°ì—ì„œ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")
    output.append("")
    output.append(f"**[ðŸ”— {law_name} ì‹ êµ¬ì¡°ë¬¸ëŒ€ë¹„í‘œ ë³´ê¸°](https://www.law.go.kr/lsScLsComp.do?lsiSeq={law_id})**")
    output.append("")
    output.append("ìœ„ ë§í¬ì—ì„œ ì¡°ë¬¸ë³„ ë³€ê²½ ì „/í›„ ë‚´ìš©ì„ ì‹œê°ì ìœ¼ë¡œ ë¹„êµí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")
    
    return "\n".join(output)

def resolve_references(content: str, context_law_name: str = None, context_law_id: str = None) -> str:
    """
    Analyze legal text to resolve:
    1. Internal References ("Article 5") - Uses context_law_id
    2. External References ("Article 10 of Building Act")
    3. Delegations ("Presidential Decree") - Finds linked Enforcement Decree
    
    Args:
        content: The text to analyze
        context_law_name: Name of the law the content belongs to (e.g. "Higher Education Act")
        context_law_id: ID of the law
    """
    logger.info(f"Resolving references (Context: {context_law_name})...")
    output = []
    
    # --- 1. explicit External References (XX Act Article YY) ---
    ext_pattern = r'([ê°€-íž£]+ë²•)\s*ì œ(\d+)ì¡°'
    ext_matches = list(set(re.findall(ext_pattern, content)))
    
    # --- 2. Internal References (Article YY) ---
    # Look for "Article YY" NOT preceded by a law name
    # We use a negative lookbehind or just simple parsing if we strictly exclude the external ones
    # Simplified regex: "ì œ\d+ì¡°"
    int_pattern = r'(?<![ê°€-íž£])ì œ(\d+)ì¡°' 
    int_matches = []
    if context_law_id:
        raw_int_matches = re.findall(int_pattern, content)
        # Filter out those that were part of external matches
        # This is a heuristic. Ideally we'd tokenize. 
        # For now, let's just collect them.
        for art_no in raw_int_matches:
            # Check if this "Article X" was captured as "Act Article X"
            is_external = False
            for ext_law, ext_art in ext_matches:
                 if ext_art == art_no and f"{ext_law} ì œ{ext_art}ì¡°" in content:
                     # This check is weak but acceptable for MVP
                     pass
            int_matches.append(art_no)
        int_matches = list(set(int_matches))

    # --- 3. Gather Content ---
    
    resolved_count = 0
    max_refs = 5
    
    # Resolve Internal
    for art_no in int_matches:
        if resolved_count >= max_refs: break
        # Avoid recursion if resolving the article itself
        # (Caller handles this, but good to be safe)
        if f"ì œ{art_no}ì¡°" in content.split('\n')[0]: continue
        
        try:
            art_text = get_statute_article_internal(context_law_id, art_no)
            if "not found" not in art_text and "Error" not in art_text:
                output.append(f"### [Internal] Je{art_no}jo\n{art_text}")
                resolved_count += 1
        except Exception as e:
            logger.error(f"Internal ref error: {e}")

    # Resolve External
    for law_name, art_no in ext_matches:
        if resolved_count >= max_refs: break
        if context_law_name and law_name in context_law_name: continue # Skip self-reference if name matches
        
        try:
            # Search for law ID
            search_res = client.search_law(law_name)
            if 'LawSearch' in search_res and 'law' in search_res['LawSearch']:
                 items = search_res['LawSearch']['law']
                 if not isinstance(items, list): items = [items]
                 target_law = items[0] # Best guess
                 
                 ext_id = target_law.get('ë²•ë ¹ì¼ë ¨ë²ˆí˜¸')
                 art_text = get_statute_article_internal(ext_id, art_no)
                 output.append(f"### [External] {law_name} Article {art_no}\n{art_text}")
                 resolved_count += 1
        except Exception as e:
             logger.error(f"External ref error: {e}")

    if not output:
        return ""
        
    final_output = ["## Referenced Articles"] + output
    return "\n\n".join(final_output)

def resolve_delegation(content: str, context_law_name: str, context_law_id: str, current_article_no: str) -> str:
    """
    If content mentions "Presidential Decree" (ëŒ€í†µë ¹ë ¹), find the corresponding Enforcement Decree article.
    Strategy:
    1. Identify target decree name: "X Act" -> "X Act Enforcement Decree"
    2. Search/Fetch that Decree.
    3. Look for articles in that Decree that reference "Act Article {current_article_no}"
       (e.g. "Pursuant to Article 20 of the Act")
    """
    if "ëŒ€í†µë ¹ë ¹" not in content and "êµ­íšŒê·œì¹™" not in content and "ëŒ€ë²•ì›ê·œì¹™" not in content:
        return ""
        
    logger.info(f"Checking delegations for {context_law_name} Art {current_article_no}")
    
    # 1. Guess Decree Name
    # Usually: Law Name + " ì‹œí–‰ë ¹" (Enforcement Decree)
    # Caution: Some laws just change "Act" to "Act Enforcement Decree"
    # But appending " ì‹œí–‰ë ¹" is safe for search smarts usually
    target_decree_name = context_law_name + " ì‹œí–‰ë ¹"
    
    # 2. Find Decree ID
    deg_id = None
    try:
        data = client.search_law(target_decree_name)
        if 'LawSearch' in data and 'law' in data['LawSearch']:
            items = data['LawSearch']['law']
            if not isinstance(items, list): items = [items]
            # Precise match preferred
            for item in items:
                if item.get('ë²•ë ¹ëª…í•œê¸€', '').replace(' ', '') == target_decree_name.replace(' ', ''):
                    deg_id = item.get('ë²•ë ¹ì¼ë ¨ë²ˆí˜¸')
                    break
            if not deg_id and items: deg_id = items[0].get('ë²•ë ¹ì¼ë ¨ë²ˆí˜¸')
    except Exception as e:
        logger.error(f"Delegation search error: {e}")
        return ""
        
    if not deg_id: return ""
    
    # 3. Scan Decree for Back-References
    # "ë²• ì œXì¡°" where X is current_article_no
    target_ref_pattern = f"ë²• ì œ{current_article_no}ì¡°"
    
    # We fetch ALL articles of the decree to scan them. 
    # This might be heavy if decree is huge, but necessary for accurate linking.
    decree_detail = client.get_law_detail(deg_id)
    if 'ë²•ë ¹' not in decree_detail: return ""
    
    decree_info = decree_detail['ë²•ë ¹']
    real_decree_name = decree_info.get('ê¸°ë³¸ì •ë³´', {}).get('ë²•ë ¹ëª…_í•œê¸€', target_decree_name)
    parsed = _parse_articles(decree_info)
    
    matches = []
    for art in parsed:
        if target_ref_pattern in art['full_text']:
            matches.append(art)
            
    if not matches:
        return f"\n\n## Delegated Legislation ({real_decree_name})\n(No specific article found referencing Act Article {current_article_no}.)"
        
    output = [f"\n\n## Delegated Legislation ({real_decree_name})"]
    for m in matches:
        output.append(f"### Article {m['no']} ({m['title']})")
        output.append(m['full_text'])
    
    return "\n".join(output)

def search_integrated_internal(query: str) -> str:
    logger.info(f"Integrated search for: {query}")
    results = {}
    def search_target(target, label):
        try:
            res = client.search_law(query, target=target)
            return label, res
        except Exception as e:
            logger.error(f"Error searching {label}: {e}")
            return label, None

    with concurrent.futures.ThreadPoolExecutor() as executor:
        futures = [
            executor.submit(search_target, "law", "Statutes"),
            executor.submit(search_target, "prec", "Precedents"),
            executor.submit(search_target, "admrul", "AdminRules")
        ]
        for future in concurrent.futures.as_completed(futures):
            label, res = future.result()
            results[label] = res
            
    output = [f"# Integrated Search Results for '{query}'\n"]
    
    statutes = results.get("Statutes", {})
    output.append("## 1. Statutes (ë²•ë ¹)")
    if statutes and 'LawSearch' in statutes and 'law' in statutes['LawSearch']:
        items = statutes['LawSearch']['law']
        if not isinstance(items, list): items = [items]
        for item in items[:3]:
            name = item.get('ë²•ë ¹ëª…í•œê¸€', '')
            id = item.get('ë²•ë ¹ì¼ë ¨ë²ˆí˜¸', '')
            date = item.get('ì‹œí–‰ì¼ìž', '')
            output.append(f"- **{name}** (Date: {date}) [ID: statute:{id}]")
    else: output.append("(No results)")
    output.append("")
        
    precs = results.get("Precedents", {})
    output.append("## 2. Precedents (íŒë¡€)")
    if precs and 'PrecSearch' in precs and 'prec' in precs['PrecSearch']:
        items = precs['PrecSearch']['prec']
        if not isinstance(items, list): items = [items]
        for item in items[:3]:
            name = item.get('ì‚¬ê±´ëª…', '')
            case_no = item.get('ì‚¬ê±´ë²ˆí˜¸', '')
            id = item.get('íŒë¡€ì¼ë ¨ë²ˆí˜¸', '')
            output.append(f"- **{case_no} {name}** [ID: prec:{id}]")
    else: output.append("(No results)")
    output.append("")

    rules = results.get("AdminRules", {})
    output.append("## 3. Administrative Rules (í–‰ì •ê·œì¹™)")
    if rules and 'AdmRulSearch' in rules and 'admrul' in rules['AdmRulSearch']:
        items = rules['AdmRulSearch']['admrul']
        if not isinstance(items, list): items = [items]
        for item in items[:3]:
            name = item.get('í–‰ì •ê·œì¹™ëª…', '')
            id = item.get('í–‰ì •ê·œì¹™ì¼ë ¨ë²ˆí˜¸', '')
            dept = item.get('ì†Œê´€ë¶€ì²˜ëª…', '')
            output.append(f"- **{name}** ({dept}) [ID: admrul:{id}]")
    else: output.append("(No results)")
    return "\n".join(output)

def smart_search_statute_internal(query: str) -> str:
    # Logic from previous smart_search_statute
    logger.info(f"Smart searching for: {query}")
    article_no = None
    
    # 1. Pattern: "ì œ103ì¡°" or "ì œ 103 ì¡°"
    kr_match = re.search(r'ì œ\s*(\d+(?:ì˜\d+)?)', query)
    
    # 2. Pattern: "Article 103"
    en_match = re.search(r'(?:Article|Art\.?)\s*(\d+(?:-\d+)?)', query, re.IGNORECASE)
    
    # 3. Pattern: "LawName 103" (Relaxed, end of string or space boundary)
    # e.g. "ë¯¼ë²• 103", "Civil Act 103"
    # We look for a number at the end of the query or preceded by space
    relaxed_match = re.search(r'(?:\s|^)(\d+(?:-\d+)?)(?:\s|$)', query)

    if kr_match:
        article_no = kr_match.group(1)
        clean_query = re.sub(r'ì œ\s*(\d+(?:ì˜\d+)?)', '', query).strip()
        # Remove trailing 'ì¡°' if valid
        clean_query = clean_query.replace('ì¡°', '').strip()
    elif en_match:
        article_no = en_match.group(1)
        clean_query = re.sub(r'(?:Article|Art\.?)\s*(\d+(?:-\d+)?)', '', query, flags=re.IGNORECASE).strip()
    elif relaxed_match:
         candidate_no = relaxed_match.group(1)
         start, end = relaxed_match.span(1)
         clean_query = (query[:start] + query[end:]).strip()
         if clean_query:
             article_no = candidate_no
         else:
             clean_query = query
    else:
        clean_query = query
            
    clean_query = re.sub(r'\bof\b', '', clean_query, flags=re.IGNORECASE).strip()
    data = client.search_law(clean_query)
    if 'LawSearch' not in data or 'law' not in data['LawSearch']:
        return f"No laws found for query: '{clean_query}'"
    items = data['LawSearch']['law']
    if not isinstance(items, list): items = [items]
    
    best_match = None
    exact_matches = [i for i in items if i.get('ë²•ë ¹ëª…í•œê¸€', '').replace(' ', '') == clean_query.replace(' ', '')]
    statute_matches = [i for i in items if i.get('ë²•ë ¹êµ¬ë¶„ëª…') == 'ë²•ë¥ ']
    
    if exact_matches:
        best_match = exact_matches[0]
        for m in exact_matches:
            if m.get('í˜„í–‰ì—°í˜ì½”ë“œ') == 'í˜„í–‰':
                best_match = m
                break
    elif statute_matches: best_match = statute_matches[0]
    else: best_match = items[0]
        
    law_name = best_match.get('ë²•ë ¹ëª…í•œê¸€', 'Unknown')
    law_id = best_match.get('ë²•ë ¹ì¼ë ¨ë²ˆí˜¸')
    if not law_id: return "Error: Selected law has no ID."
    
    logger.info(f"Selected law: {law_name} ({law_id})")
    detail_data = client.get_law_detail(law_id)
    if 'ë²•ë ¹' not in detail_data: return "Error: Could not retrieve law details."
    law_info = detail_data['ë²•ë ¹']
    parsed_articles = _parse_articles(law_info)
    
    if article_no:
        # Priority Search for Content
        for art in parsed_articles:
            if art['no'] == article_no and art.get('type') == 'ì¡°ë¬¸':
                return f"# {law_name} ì œ{article_no}ì¡°\n\n{art['full_text']}"
        
        # Fallback to any match
        for art in parsed_articles:
             if art['no'] == article_no:
                return f"# {law_name} ì œ{article_no}ì¡°\n\n{art['full_text']}"
                
        return f"Article {article_no} not found in {law_name}."
    else:
        output = [f"# {law_name}"]
        enforce_date = law_info.get('ê¸°ë³¸ì •ë³´', {}).get('ì‹œí–‰ì¼ìž', '')
        output.append(f"Enforcement Date: {enforce_date}")
        output.append("")
        output.append("## Table of Contents (First 30 Articles)")
        last_no = None
        count = 0
        for art in parsed_articles:
            if art['no'] == last_no and not art['title']: continue
            display_title = art['title'] if art['title'] else "(No Title)"
            output.append(f"- ì œ{art['no']}ì¡°: {display_title}")
            last_no = art['no']
            count += 1
            if count >= 30:
                output.append(f"... and {len(parsed_articles) - 30} more articles.")
                break
        output.append("")
        output.append("To read a specific article, try searching 'LawName Article X'.")
        return "\n".join(output)
